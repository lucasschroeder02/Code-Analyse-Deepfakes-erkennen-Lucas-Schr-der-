{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4HuL3B1UNwS"
      },
      "source": [
        "## Installations and Import Statements \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dbRGB3drUNw2",
        "outputId": "de6091e7-83d6-44fb-ea15-a8217cd7b8d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pip in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\lib\\site-packages (25.0.1)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.8/1.8 MB 12.1 MB/s eta 0:00:00\n",
            "Installing collected packages: pip\n",
            "Successfully installed pip-25.3\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F0ULyxPmUNw-",
        "outputId": "b56fbf4a-22d7-45aa-f2ca-78ec348b0c08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tensorflow in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.20.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (2.3.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (6.33.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (2.32.5)\n",
            "Requirement already satisfied: setuptools in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (80.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (2.2.6)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.6.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: pillow in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
            "Requirement already satisfied: namex in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TlxQa8YjUNxA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: dlib in c:\\users\\lycas02\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (20.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install dlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QKZZUZFnUNxB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\lycas02\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, \"object\"):\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'experimental' from 'tensorflow.keras.mixed_precision' (C:\\Users\\lycas02\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\_tf_keras\\keras\\mixed_precision\\__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmixed_precision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m experimental \u001b[38;5;28;01mas\u001b[39;00m mixed_precision\n\u001b[32m     20\u001b[39m policy = mixed_precision.Policy(\u001b[33m'\u001b[39m\u001b[33mmixed_float16\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;66;03m#made change\u001b[39;00m\n\u001b[32m     21\u001b[39m mixed_precision.set_policy(policy)\n",
            "\u001b[31mImportError\u001b[39m: cannot import name 'experimental' from 'tensorflow.keras.mixed_precision' (C:\\Users\\lycas02\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\_tf_keras\\keras\\mixed_precision\\__init__.py)"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os \n",
        "import dlib\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import os\n",
        "from random import shuffle\n",
        "from tqdm import tqdm_notebook\n",
        "import itertools\n",
        "import shutil\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
        "policy = mixed_precision.Policy('mixed_float16')#made change\n",
        "mixed_precision.set_policy(policy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHmij1eYUNxE"
      },
      "source": [
        "# Functions for Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZf36JS5UNxH"
      },
      "outputs": [],
      "source": [
        "def get_input(folder):\n",
        "    images = np.zeros((num_images,128,128,3), dtype = np.float32)\n",
        "    imagespath = range(0,2054)\n",
        "    for i in range(num_images):\n",
        "        a= str(imagespath[i]).zfill(2)\n",
        "        img = cv2.resize(plt.imread(folder+a+'.jpg'), (128, 128), interpolation=cv2.INTER_CUBIC)/255\n",
        "        #print(a)\n",
        "        images[i] = img\n",
        "        \n",
        "    return [images]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXnUC5foUNxJ"
      },
      "source": [
        "## CNN: Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1n4eWuOHUNxK"
      },
      "outputs": [],
      "source": [
        "model_path = 'models/CNN50_Tom_Cruise/'\n",
        "attempt = 0\n",
        "foldername = model_path+\"_xceptionimagenet_attempt\"+str(attempt)+\"/\"\n",
        "num_images = 2054\n",
        "img_size = 128\n",
        "modelname = foldername+\"_xceptionimagenet_\"+str(num_images)+\"_\"+str(img_size)\n",
        "cnn_model = load_model(modelname+\".h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FL9zooaEUNxL"
      },
      "outputs": [],
      "source": [
        "test_folder=\"../Tom_Cruise_Dataset/Tom_Cruise_dataset_two_faces/testing/real/TOM CRUISE 2020 Deepfake  VFX Breakdown  Side by Side_1080p_Trim/\"\n",
        "batch_input = get_input(test_folder)\n",
        "batch_x = np.array(batch_input)\n",
        "probr1 = cnn_model.predict(batch_x)\n",
        "test_folder=\"../Tom_Cruise_Dataset/Tom_Cruise_dataset_two_faces/testing/fake/TOM CRUISE 2020 Deepfake  VFX Breakdown  Side by Side_1080p_Trim/\"\n",
        "batch_input = get_input(test_folder)\n",
        "batch_x = np.array(batch_input)\n",
        "probf1 = cnn_model.predict(batch_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiFjzHgHUNxN"
      },
      "source": [
        "# CNN:Reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW7nxvM_UNxO"
      },
      "outputs": [],
      "source": [
        "p = \"../mmod_human_face_detector.dat\"\n",
        "cnn_face_detector = dlib.cnn_face_detection_model_v1(p)\n",
        "for i in range(1):\n",
        "    try:\n",
        "        vidcap = cv2.VideoCapture('../Tom_Cruise/TOM CRUISE 2020 Deepfake VFX Breakdown Side by Side_1080p_Trim.mp4')\n",
        "        success,image = vidcap.read()\n",
        "        count = 0\n",
        "        success = True\n",
        "        frames_path=\"../Tom_Cruise/Completeframe/TOM_CRUISE_2020_Deepfake_VFX_Breakdown_Side_by_Side_1080p_Trim/\"\n",
        "        print(\"NOW FRAMING\")\n",
        "        imagespath = range(0,2241)\n",
        "        kr=0\n",
        "        kf=0\n",
        "        prediction_folder_path='Tom_Cruise/Reconstructed/frames1/'\n",
        "        Path(prediction_folder_path).mkdir(parents=True, exist_ok = True)\n",
        "        real_count_real=0\n",
        "        fake_count_real=0\n",
        "        real_count_fake=0\n",
        "        fake_count_fake=0\n",
        "        print(\"NOW DETECTING\")\n",
        "        m=0\n",
        "        #Perform face detection\n",
        "        for it in range(0,2241):\n",
        "            #try:\n",
        "            a= str(imagespath[it]).zfill(4)\n",
        "            image=cv2.imread(frames_path+a+'.jpg')\n",
        "            \n",
        "            if image is None:\n",
        "                print(\"Could not read input image\")\n",
        "                continue\n",
        "\n",
        "            faces_cnn = cnn_face_detector(image[:,:,::-1],0)\n",
        "            \n",
        "            if(len(faces_cnn)!=2):\n",
        "                print(\"Total Faces =     \" ,len(faces_cnn))\n",
        "                cv2.imwrite(prediction_folder_path+a+'.jpg',image)\n",
        "                continue\n",
        "            else:\n",
        "                odd=1\n",
        "                for face in faces_cnn:\n",
        "                    \n",
        "                    x = face.rect.left()\n",
        "                    y = face.rect.top()\n",
        "                    w= face.rect.right() - x\n",
        "                    h= face.rect.bottom() - y \n",
        "                    y1 =y-50\n",
        "                    y2= y+h+30\n",
        "                    x1=x-15\n",
        "                    x2=x+w+50\n",
        "                    \n",
        "                    if odd==1:\n",
        "                        odd=0\n",
        "                        result=probr1[0,kr,0]\n",
        "                        kr+=1\n",
        "                        if(kr==2054):\n",
        "                            print(a)\n",
        "                        if(result<0.5):\n",
        "                            print(\"real\")\n",
        "                            cv2.rectangle(image, (x1,y1), (x2,y2), (0,255,0), 2)\n",
        "                            cv2.putText(image, 'REAL:'+str(result), (30, 250), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (35,102,11), thickness=2,lineType=cv2.LINE_AA) \n",
        "                            real_count_real+=1\n",
        "                            \n",
        "                        else:\n",
        "                            print(\"fake\")\n",
        "                            cv2.rectangle(image, (x1,y1), (x2,y2), (0,0,255), 2)\n",
        "                            cv2.putText(image, 'FAKE:'+str(result), (30, 250), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (0,0,255), thickness=2,lineType=cv2.LINE_AA) \n",
        "                            fake_count_real+=1\n",
        "                        real_count= real_count_real\n",
        "                        fake_count= fake_count_real\n",
        "                        cv2.putText(image, 'REAL:'+str(real_count), (30, 400), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (35,102,11),thickness=2, lineType=cv2.LINE_AA) \n",
        "                        cv2.putText(image, 'FAKE:'+str(fake_count), (30, 450), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (0,0,255), thickness=2,lineType=cv2.LINE_AA) \n",
        "                        cv2.imwrite(prediction_folder_path+a+'.jpg',image)\n",
        "                        \n",
        "                    else:\n",
        "                        odd=1\n",
        "                        result=probf1[0,kf,0]\n",
        "                        kf+=1\n",
        "                        if(kf==2054):\n",
        "                            print(a)\n",
        "                        if(result<0.5):\n",
        "                            print(\"real\")\n",
        "                            cv2.rectangle(image, (x1,y1), (x2,y2), (0,255,0), 2)\n",
        "                            cv2.putText(image, 'REAL:'+str(result), (1600, 250), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (35,102,11), thickness=2,lineType=cv2.LINE_AA) \n",
        "                            real_count_fake+=1\n",
        "                            \n",
        "                        else:\n",
        "                            print(\"fake\")\n",
        "                            cv2.rectangle(image, (x1,y1), (x2,y2), (0,0,255), 2)\n",
        "                            cv2.putText(image, 'FAKE:'+str(result), (1600, 250), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (0,0,255), thickness=2,lineType=cv2.LINE_AA) \n",
        "                            fake_count_fake+=1\n",
        "                        real_count= real_count_fake\n",
        "                        fake_count= fake_count_fake\n",
        "                        cv2.putText(image, 'REAL:'+str(real_count), (1600, 400), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (35,102,11),thickness=2, lineType=cv2.LINE_AA) \n",
        "                        cv2.putText(image, 'FAKE:'+str(fake_count), (1600, 450), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (0,0,255), thickness=2,lineType=cv2.LINE_AA) \n",
        "                        cv2.imwrite(prediction_folder_path+a+'.jpg',image)\n",
        "                print(it)\n",
        "        img_array = []\n",
        "        for j in range(num_images):\n",
        "            \n",
        "            a= str(imagespath[j]).zfill(4)\n",
        "            \n",
        "            try:    \n",
        "                img = cv2.imread(prediction_folder_path+a+'.jpg')\n",
        "                height, width, layers = img.shape\n",
        "                size = (width,height)\n",
        "                img_array.append(img)\n",
        "            except:\n",
        "                continue\n",
        "        print(\"NOW RECONSTRUCTING\")\n",
        "        save_path='Tom_Cruise/Reconstructed/rvideo/'\n",
        "        Path(save_path).mkdir(parents=True, exist_ok = True)\n",
        "        out = cv2.VideoWriter(save_path+'Tom_Cruise_video'+'.mp4',cv2.VideoWriter_fourcc(*'MP4V'), 30, size)\n",
        "\n",
        "        for i in range(len(img_array)):\n",
        "            out.write(img_array[i])\n",
        "        out.release()\n",
        "        print(\"VIDEO COMPLETED:\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoLVcJK9UNxc"
      },
      "source": [
        "## Video Deepfake Detection Using LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MuEsA-kUNxd"
      },
      "source": [
        "Required Function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRONFsQGUNxf"
      },
      "outputs": [],
      "source": [
        "num_images = 20\n",
        "img_size = 128\n",
        "\n",
        "def get_input( folder):\n",
        "    images = np.zeros((num_images,img_size,img_size,3), dtype = np.float32)\n",
        "    imagespath = [f for f in os.listdir(folder+\"/\") if 'jpg' in f]\n",
        "    #print(dataset+label+folder)\n",
        "    for i in range(num_images):\n",
        "        img = cv2.resize(plt.imread(folder+\"/\"+imagespath[i]), (img_size, img_size), interpolation=cv2.INTER_CUBIC)/255\n",
        "        images[i] = img\n",
        "    return [images]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBWrS4IHUNxg"
      },
      "source": [
        "CNN+ LSTM Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkVx3vIhUNxh"
      },
      "outputs": [],
      "source": [
        "test_folder1=\"../Tom_Cruise_Dataset/Tom_Cruise_dataset_two_faces/testing/fake/TOM CRUISE 2020 Deepfake  VFX Breakdown  Side by Side_1080p_Trim\"\n",
        "test_folder2=\"../Tom_Cruise_Dataset/Tom_Cruise_dataset_two_faces/testing/real/TOM CRUISE 2020 Deepfake  VFX Breakdown  Side by Side_1080p_Trim\"\n",
        "\n",
        "batch_input1=get_input(test_folder1)\n",
        "batchx1=np.array(batch_input1)\n",
        "\n",
        "batch_input2=get_input(test_folder2)\n",
        "batchx2=np.array(batch_input2)\n",
        "\n",
        "model=load_model(\"All_Models/Tom_Cruise/tom_cruise_xceptionimagenet_attempt1/_xceptionimagenet_2054_128_finetuned.h5\")\n",
        "result1=model.predict(batchx2)\n",
        "print(result1)\n",
        "\n",
        "result2=model.predict(batchx1)\n",
        "print(result2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkif1y84UNxi"
      },
      "source": [
        "CNN + LSTM Reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ia3pEwIoUNxk"
      },
      "outputs": [],
      "source": [
        "\n",
        "video_folder=\"../Tom_Cruise/Completeframe/TOM_CRUISE_2020_Deepfake_VFX_Breakdown_Side_by_Side_1080p_Trim\"\n",
        "\n",
        "path_names=video_folder.split('/')\n",
        "prediction_folder=\"Predictions/\"+path_names[-1]+\"/predicted_frames\"\n",
        "ssh = Path(prediction_folder)\n",
        "ssh.mkdir(parents=True)\n",
        "\n",
        "frames=os.listdir(video_folder+\"/\")\n",
        "frames.sort()\n",
        "\n",
        "if result1[0][0]>=0.5:\n",
        "    print(result1)\n",
        "    for i in range(0,2241):\n",
        "        if frames[i] ==\".ipynb_checkpoints\":\n",
        "            continue\n",
        "        image=cv2.imread(video_folder+\"/\"+frames[i])\n",
        "        if i<=216:\n",
        "            destination=cv2.rectangle(image, (3,100), ((image.shape[1]//2)-20,image.shape[0]-100),(0,0,255), 5) \n",
        "        elif i<=290:\n",
        "            destination=cv2.rectangle(image, (3,100), ((image.shape[1]//2)-20-50,image.shape[0]-100),(0,0,255), 5) \n",
        "        else:\n",
        "            destination=cv2.rectangle(image, (3,100), ((image.shape[1]//2)-20+30,image.shape[0]-100),(0,0,255), 5) \n",
        "        #wide,length,_=(destination.shape)\n",
        "        cv2.putText(destination, 'Fake:'+str(round(result1[0][0],4)), (30,image.shape[0]-100-35), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (0,0,255),thickness=2, lineType=cv2.LINE_AA)\n",
        "        cv2.imwrite(prediction_folder+\"/\"+frames[i],destination)\n",
        "else:\n",
        "    print(result1)\n",
        "    for i in range(0,2241):\n",
        "        if frames[i] ==\".ipynb_checkpoints\":\n",
        "            continue\n",
        "        image=cv2.imread(video_folder+\"/\"+frames[i])\n",
        "        if i<=216:\n",
        "            destination=cv2.rectangle(image, (3,100), ((image.shape[1]//2)-20,image.shape[0]-100),(0,255,0), 5) \n",
        "        elif i<=290:\n",
        "            destination=cv2.rectangle(image, (3,100), ((image.shape[1]//2)-20-50,image.shape[0]-100),(0,255,0), 5) \n",
        "        else:\n",
        "            destination=cv2.rectangle(image, (3,100), ((image.shape[1]//2)-20+30,image.shape[0]-100),(0,255,0), 5) \n",
        "        #wide,length,_=(destination.shape)\n",
        "        cv2.putText(destination, 'Real:'+str(round(result1[0][0],4)), (30,image.shape[0]-100-35), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (35,102,11),thickness=2, lineType=cv2.LINE_AA)\n",
        "        cv2.imwrite(prediction_folder+\"/\"+frames[i],destination)\n",
        "if result2[0][0]>=0.5:\n",
        "    print(result1)\n",
        "    for i in range(0,2241):\n",
        "        if frames[i] ==\".ipynb_checkpoints\":\n",
        "            continue\n",
        "        image=cv2.imread(prediction_folder+\"/\"+frames[i])\n",
        "        if i<=216:\n",
        "            destination=cv2.rectangle(image,  ((image.shape[1]//2)-15,100),((image.shape[1])-3,image.shape[0]-100),(0,0,255), 5) \n",
        "        elif i<=290:\n",
        "            destination=cv2.rectangle(image,  ((image.shape[1]//2)-20-45,100),((image.shape[1])-3,image.shape[0]-100),(0,0,255), 5) \n",
        "        else:\n",
        "            destination=cv2.rectangle(image, ((image.shape[1]//2)-20+35,100),((image.shape[1])-3,image.shape[0]-100),(0,0,255), 5) \n",
        "        wide,length,_=(destination.shape)\n",
        "        cv2.putText(destination, 'Fake:'+str(round(result2[0][0],4)), ((image.shape[1])-330,wide-100-35), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (0,0,255),thickness=2, lineType=cv2.LINE_AA)\n",
        "        cv2.imwrite(prediction_folder+\"/\"+frames[i],destination)\n",
        "else:\n",
        "    print(result2)\n",
        "    print(result1)\n",
        "    for i in range(0,2241):\n",
        "        if frames[i] ==\".ipynb_checkpoints\":\n",
        "            continue\n",
        "        image=cv2.imread(prediction_folder+\"/\"+frames[i])\n",
        "        if i<=216:\n",
        "            destination=cv2.rectangle(image,((image.shape[1]//2)-15,100),((image.shape[1])-3,image.shape[0]-100),(0,255,0), 5) \n",
        "        elif i<=290:\n",
        "            destination=cv2.rectangle(image,((image.shape[1]//2)-20-45,100),((image.shape[1])-3,image.shape[0]-100),(0,255,0), 5) \n",
        "        else:\n",
        "            destination=cv2.rectangle(image,((image.shape[1]//2)-20+35,100),((image.shape[1])-3,image.shape[0]-100),(0,255,0), 5) \n",
        "        wide,length,_=(destination.shape)\n",
        "        cv2.putText(destination, 'Real:'+str(round(result2[0][0],4)), ((image.shape[1])-330,wide-100-35), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (0,255,0),thickness=2, lineType=cv2.LINE_AA)\n",
        "        cv2.imwrite(prediction_folder+\"/\"+frames[i],destination)\n",
        "\n",
        "        \n",
        "images=[]\n",
        "files=os.listdir(prediction_folder)\n",
        "files.sort()\n",
        "print(files)\n",
        "\n",
        "for filename in files:\n",
        "    try:    \n",
        "        img = cv2.imread(prediction_folder+\"/\"+filename)\n",
        "        height, width, layers = img.shape\n",
        "        height, width, layers = img.shape\n",
        "        size = (width,height)\n",
        "        images.append(img)\n",
        "    except:\n",
        "        continue\n",
        "        \n",
        "print(\"NOW RECONSTRUCTING---\")\n",
        "    \n",
        "out = cv2.VideoWriter(\"Predictions/\"+path_names[-1]+'/predicted_video30.mp4',cv2.VideoWriter_fourcc(*'MP4V'), 30, size)\n",
        "\n",
        "for i in range(len(images)):\n",
        "    out.write(images[i])\n",
        "\n",
        "out.release()\n",
        "\n",
        "print(\"VIDEO COMPLETED!!!\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTaKoB6PUNxp"
      },
      "source": [
        "## Video Deepfake Detection Using GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kxrc-FB0UNxr"
      },
      "outputs": [],
      "source": [
        "epochs = 40\n",
        "batch_size = 16\n",
        "\n",
        "train_spe = len(os.listdir(dataset+\"/\"+'real'))//batch_size\n",
        "print(train_spe)\n",
        "val_spe = len(os.listdir(dataset+\"/\"+'real'))//batch_size\n",
        "print(val_spe)\n",
        "test_spe = len(os.listdir(dataset+\"/\"+'real'))//(batch_size)\n",
        "print(test_spe)\n",
        "\n",
        "print('For GRU:')\n",
        "train_datagen = video_data_generator(dataset,'train', batch_size = batch_size)\n",
        "val_datagen = video_data_generator(dataset,'val', batch_size = batch_size)\n",
        "test_datagen = video_data_generator(dataset,'test', batch_size = batch_size)\n",
        "print(\"For model without fine-tuning validation loss and validation accuracy is:\")\n",
        "cnngru_model = load_model('models/TDCNN_GRU_20_Epochs/multiframe_full_xceptionimagenet_attempt2/multiframe_full_xceptionimagenet_10_128.h5')\n",
        "test_datagen = video_data_generator(dataset,'test', batch_size = batch_size)\n",
        "start_time1 = time.clock()\n",
        "print(cnngru_model.evaluate(test_datagen,steps=2*test_spe,verbose=0))\n",
        "current_time1= time.clock()\n",
        "print(\"Evaluation time required without fine tuning:\")\n",
        "print(current_time1-start_time1)\n",
        "\n",
        "yhat_classes=cnngru_model.predict(test_datagen,steps=2*test_spe,verbose=0)\n",
        "accuracy = accuracy_score(testy, yhat_classes.round())\n",
        "print('Accuracy:   ',accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(testy, yhat_classes.round())\n",
        "print(\"Precision:  \",precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(testy, yhat_classes.round())\n",
        "print('Recall:     ',recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(testy, yhat_classes.round())\n",
        "print('f1 score:   ',f1)\n",
        "\n",
        "\n",
        "print(\"For model with fine-tuning validation loss and validation accuracy is:\")\n",
        "cnngru_model = load_model('models/TDCNN_GRU_20_Epochs/multiframe_full_xceptionimagenet_attempt2/multiframe_full_xceptionimagenet_10_128_finetuned.h5')\n",
        "test_datagen = video_data_generator(dataset,'test', batch_size = batch_size)\n",
        "start_time_1 = time.clock()\n",
        "print(cnngru_model.evaluate(test_datagen,steps=2*test_spe,verbose=0))\n",
        "current_time_1 = time.clock()\n",
        "print(\"Evaluation time required with fine tuning:\")\n",
        "print(current_time_1-start_time_1)\n",
        "\n",
        "yhat_classes=cnngru_model.predict(test_datagen,steps=2*test_spe,verbose=0)\n",
        "accuracy = accuracy_score(testy, yhat_classes.round())\n",
        "print('Accuracy:   ',accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(testy, yhat_classes.round())\n",
        "print(\"Precision:  \",precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(testy, yhat_classes.round())\n",
        "print('Recall:     ',recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(testy, yhat_classes.round())\n",
        "print('f1 score:   ',f1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Video Deepfake Detection Using CNN, LSTM, GRU.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
